"""
src/ai_analysis/ai_analysis.py

AI ile yorum analizi ve Ã¶zet Ã§Ä±karma modÃ¼lÃ¼.
- OpenAI GPT kullanarak yorumlarÄ± Ã¶zetler
- Chunk-based processing (bÃ¼yÃ¼k yorum setleri iÃ§in)
- Retry logic ile API hatalarÄ±nÄ± yÃ¶netir
"""

import json
import time
import logging
from typing import List, Dict, Optional
from dataclasses import dataclass
from enum import Enum

import pandas as pd
import openai
from openai import OpenAI
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
)

from src.config.config_settings import settings


logger = logging.getLogger(__name__)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ENUMS & DATACLASSES
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class Sentiment(Enum):
    """ÃœrÃ¼n duygu kategorileri."""
    VERY_POSITIVE = "Ã‡ok Olumlu"
    POSITIVE = "Olumlu"
    NEUTRAL = "NÃ¶tr"
    NEGATIVE = "Olumsuz"
    VERY_NEGATIVE = "Ã‡ok Olumsuz"


@dataclass
class ReviewSummary:
    """AI Ã¶zet sonucunu tutan dataclass."""
    product_id: str
    overall_summary: str
    positive_aspects: List[str]
    negative_aspects: List[str]
    price_performance: str
    packaging_quality: str
    shipping_speed: str
    sentiment: str
    reviews_analyzed: int

    def to_dict(self) -> Dict:
        """CSV'ye kaydet iÃ§in dict'e Ã§evir."""
        return {
            "product_id": self.product_id,
            "ai_summary": self.overall_summary,
            "positive_points": " | ".join(self.positive_aspects),
            "negative_points": " | ".join(self.negative_aspects),
            "price_performance": self.price_performance,
            "packaging": self.packaging_quality,
            "shipping": self.shipping_speed,
            "sentiment": self.sentiment,
            "reviews_count": self.reviews_analyzed,
        }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LLM CLIENT  (OpenAI sarÄ±cÄ±)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class LLMClient:
    """
    OpenAI API ile konuÅŸan client.

    Ã–zellikler:
    - Otomatik retry (RateLimitError, APIError)
    - Token kullanÄ±m takibi
    - Logging
    """

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or settings.OPENAI_API_KEY

        if not self.api_key:
            raise ValueError(
                "OPENAI_API_KEY bulunamadÄ±! "
                ".env dosyasÄ±na ekleyin veya environment variable olarak tanÄ±mlayÄ±n."
            )

        self.client = OpenAI(api_key=self.api_key)
        self.model = settings.AI_MODEL

        # KullanÄ±m istatistikleri
        self.total_requests = 0
        self.total_tokens = 0

        logger.info(f"LLM Client hazÄ±r â†’ model: {self.model}")

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((openai.RateLimitError, openai.APIError)),
    )
    def generate(self, prompt: str, max_tokens: int = 1000) -> str:
        """
        OpenAI'a prompt gÃ¶nderir, yanÄ±t dÃ¶ndÃ¼rÃ¼r.

        Args:
            prompt: GÃ¶nderilecek prompt metni
            max_tokens: Max Ã§Ä±ktÄ± token sayÄ±sÄ±

        Returns:
            Yapay zeka yanÄ±tÄ± (string)
        """
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=max_tokens,
                temperature=0.7,
            )

            # Ä°statistik gÃ¼ncelle
            self.total_requests += 1
            if response.usage:
                self.total_tokens += response.usage.total_tokens

            content = response.choices[0].message.content
            logger.debug(f"YanÄ±t geldi: {len(content)} karakter")
            return content

        except openai.RateLimitError:
            logger.warning("Rate limit doldu, 60s beklenecek...")
            time.sleep(60)
            raise  # retry decorator tekrar deneyecek

        except openai.APIError as e:
            logger.error(f"API hata: {e}")
            raise

    def get_usage_stats(self) -> Dict:
        """KullanÄ±m istatistiklerini dÃ¶ndÃ¼r."""
        return {
            "total_requests": self.total_requests,
            "total_tokens": self.total_tokens,
        }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PROMPTS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CHUNK_PROMPT = """AÅŸaÄŸÄ±da bir Ã¼rÃ¼ne ait kullanÄ±cÄ± yorumlarÄ± bulunmaktadÄ±r.
Bu yorumlara dayanarak kÄ±sa ve objektif bir Ã¶zet Ã§Ä±kar.

Åžu konulara deÄŸin:
- Genel deÄŸerlendirme
- Olumlu yÃ¶nler  
- Olumsuz yÃ¶nler
- Fiyat / performans
- Paketleme kalitesi
- Kargo hÄ±zÄ±

Yorumlar:
{reviews}

Ã–zet:"""


FINAL_PROMPT = """AÅŸaÄŸÄ±da bir Ã¼rÃ¼n hakkÄ±nda farklÄ± yorum gruplarÄ±ndan Ã§Ä±karÄ±lmÄ±ÅŸ Ã¶zetler var.
Bu Ã¶zetleri birleÅŸtirerek tek bir kapsamlÄ± deÄŸerlendirme oluÅŸtur.

SADECE aÅŸaÄŸÄ±daki JSON formatÄ±nda yanÄ±t ver, baÅŸka hiÃ§bey ÅŸey yazma:
{{
  "overall_summary": "...",
  "positive_aspects": ["...", "..."],
  "negative_aspects": ["...", "..."],
  "price_performance": "...",
  "packaging_quality": "...",
  "shipping_speed": "...",
  "sentiment": "Olumlu veya NÃ¶tr veya Olumsuz"
}}

Ã–zetler:
{summaries}
"""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# REVIEW SUMMARIZER
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class ReviewSummarizer:
    """
    ÃœrÃ¼n yorumlarÄ±nÄ± AI ile Ã¶zetleyen sÄ±nÄ±f.

    NasÄ±l Ã§alÄ±ÅŸÄ±r:
    1. YorumlarÄ± chunk_size'luk gruplara ayÄ±rÄ±r
    2. Her grubu ayrÄ±ca Ã¶zetletir (CHUNK_PROMPT)
    3. TÃ¼m Ã¶zet parÃ§alarÄ±nÄ± tek bir Ã¶zete birleÅŸtir (FINAL_PROMPT)
    """

    def __init__(self, llm_client: LLMClient):
        self.llm = llm_client
        self.chunk_size = settings.CHUNK_SIZE
        logger.info(f"ReviewSummarizer hazÄ±r â†’ chunk_size: {self.chunk_size}")

    def summarize(
        self, product_id: str, reviews: List[str]
    ) -> ReviewSummary:
        """
        Bir Ã¼rÃ¼nÃ¼n yorumlarÄ±nÄ± analiz eder ve Ã¶zet Ã¼retir.

        Args:
            product_id: ÃœrÃ¼n ID'si
            reviews: Yorum listesi

        Returns:
            ReviewSummary dataclass
        """
        if not reviews:
            logger.warning(f"{product_id}: Yorum yok, boÅŸ Ã¶zet dÃ¶ndÃ¼rÃ¼lÃ¼yor.")
            return self._empty_summary(product_id)

        logger.info(f"[{product_id}] {len(reviews)} yorum analiz ediliyor...")

        try:
            # Step 1: Chunk'lara ayÄ±r ve her birini Ã¶zetle
            chunk_summaries = self._process_chunks(reviews)

            if not chunk_summaries:
                return self._empty_summary(product_id)

            # Step 2: TÃ¼m Ã¶zet parÃ§alarÄ±nÄ± birleÅŸtir
            final = self._generate_final_summary(chunk_summaries)

            return ReviewSummary(
                product_id=product_id,
                overall_summary=final.get("overall_summary", ""),
                positive_aspects=final.get("positive_aspects", []),
                negative_aspects=final.get("negative_aspects", []),
                price_performance=final.get("price_performance", ""),
                packaging_quality=final.get("packaging_quality", ""),
                shipping_speed=final.get("shipping_speed", ""),
                sentiment=final.get("sentiment", "NÃ¶tr"),
                reviews_analyzed=len(reviews),
            )

        except Exception as e:
            logger.error(f"[{product_id}] Ã–zet Ã¼retim hatasÄ±: {e}", exc_info=True)
            return self._error_summary(product_id, str(e))

    # â”€â”€ Chunk iÅŸleme â”€â”€
    def _process_chunks(self, reviews: List[str]) -> List[str]:
        """YorumlarÄ± gruplara ayÄ±rÄ±r, her grubu ayrÄ±ca Ã¶zetler."""
        chunks = [
            reviews[i : i + self.chunk_size]
            for i in range(0, len(reviews), self.chunk_size)
        ]

        summaries = []
        for idx, chunk in enumerate(chunks, 1):
            try:
                review_text = "\n".join(chunk)
                prompt = CHUNK_PROMPT.format(reviews=review_text)

                result = self.llm.generate(prompt=prompt, max_tokens=500)
                summaries.append(result)

                logger.debug(f"  Chunk {idx}/{len(chunks)} tamamlandÄ±")
                time.sleep(1.5)  # Rate limit koruma

            except Exception as e:
                logger.warning(f"  Chunk {idx} baÅŸarÄ±sÄ±z: {e}")
                continue

        return summaries

    # â”€â”€ Final Ã¶zet â”€â”€
    def _generate_final_summary(self, chunk_summaries: List[str]) -> Dict:
        """TÃ¼m chunk Ã¶zetlerini tek JSON'a birleÅŸtir."""
        summaries_text = "\n\n---\n\n".join(chunk_summaries)
        prompt = FINAL_PROMPT.format(summaries=summaries_text)

        raw_result = self.llm.generate(prompt=prompt, max_tokens=800)

        # JSON parse et
        try:
            # EÄŸer markdown code block iÃ§indeyse temizle
            cleaned = raw_result.strip()
            if cleaned.startswith("```"):
                cleaned = cleaned.split("```")[1]
                if cleaned.startswith("json"):
                    cleaned = cleaned[4:]
            cleaned = cleaned.strip()

            return json.loads(cleaned)

        except json.JSONDecodeError:
            # JSON parse baÅŸarÄ±sÄ±z olursa raw text dÃ¶ndÃ¼r
            logger.warning("JSON parse baÅŸarÄ±sÄ±z, raw text kullanÄ±lÄ±yor")
            return {
                "overall_summary": raw_result[:500],
                "positive_aspects": [],
                "negative_aspects": [],
                "price_performance": "Analiz edilemedi",
                "packaging_quality": "Analiz edilemedi",
                "shipping_speed": "Analiz edilemedi",
                "sentiment": "NÃ¶tr",
            }

    # â”€â”€ BoÅŸ/Hata Ã¶zetleri â”€â”€
    def _empty_summary(self, product_id: str) -> ReviewSummary:
        return ReviewSummary(
            product_id=product_id,
            overall_summary="Yeterli yorum bulunamadÄ±.",
            positive_aspects=[],
            negative_aspects=[],
            price_performance="â€”",
            packaging_quality="â€”",
            shipping_speed="â€”",
            sentiment="NÃ¶tr",
            reviews_analyzed=0,
        )

    def _error_summary(self, product_id: str, error: str) -> ReviewSummary:
        return ReviewSummary(
            product_id=product_id,
            overall_summary=f"Analiz hatasÄ±: {error}",
            positive_aspects=[],
            negative_aspects=[],
            price_performance="â€”",
            packaging_quality="â€”",
            shipping_speed="â€”",
            sentiment="NÃ¶tr",
            reviews_analyzed=0,
        )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ANA PIPELINE FONKSIYONU
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_ai_analysis(
    reviews_csv: str = None,
    output_csv: str = None,
) -> pd.DataFrame:
    """
    CSV'deki yorumlarÄ± oku, AI Ã¶zet Ã¼ret, sonuÃ§larÄ± kaydet.

    Args:
        reviews_csv: Yorum CSV dosyasÄ± yolu
        output_csv: Ã–zet CSV dosyasÄ± yolu

    Returns:
        Ã–zet DataFrame
    """
    if reviews_csv is None:
        reviews_csv = str(settings.RAW_DATA_DIR / settings.REVIEWS_CSV)
    if output_csv is None:
        output_csv = str(settings.PROCESSED_DATA_DIR / settings.AI_SUMMARIES_CSV)

    logger.info(f"ðŸ“‚ Yorumlar okunuyor: {reviews_csv}")

    # CSV oku
    df = pd.read_csv(reviews_csv)
    grouped = df.groupby("product_id")["review"].apply(list)

    # AI components
    llm = LLMClient()
    summarizer = ReviewSummarizer(llm)

    # Her Ã¼rÃ¼n iÃ§in Ã¶zet Ã¼ret
    results = []
    total = len(grouped)

    for idx, (product_id, review_list) in enumerate(grouped.items(), 1):
        logger.info(f"[{idx}/{total}] {product_id} iÅŸleniyor...")

        summary = summarizer.summarize(product_id, review_list)
        results.append(summary.to_dict())

    # SonuÃ§larÄ± kaydet
    result_df = pd.DataFrame(results)
    result_df.to_csv(output_csv, index=False)

    logger.info(f"ðŸ’¾ Ã–zetler kaydedildi: {output_csv}")
    logger.info(f"ðŸ“Š API kullanÄ±m: {llm.get_usage_stats()}")

    return result_df


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ã‡ALIÅžTIRMA
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    )

    print("ðŸ¤– AI Analysis baÅŸlÄ±yor...\n")
    result = run_ai_analysis()
    print(f"\nâœ… TamamlandÄ±! {len(result)} Ã¼rÃ¼n analiz edildi.")